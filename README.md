# ğŸ§©âœ¨ Charivo

**A modular Live2D + LLM framework for interactive character experiences**

Charivo lets you create interactive AI characters with Live2D animations, voice synthesis, and natural language conversations. Mix and match components like LEGO blocks - swap LLM providers, renderers, TTS engines, and more with ease! âœ¨

## âœ¨ Features

- ğŸ§© **Live2D Integration** - Bring characters to life with smooth 2D animations
- ğŸ¤– **LLM Support** - Connect to OpenAI or implement custom LLM adapters
- ğŸ”Š **Text-to-Speech** - Built-in TTS with Web Speech API
- ğŸ“¦ **Modular Architecture** - Plugin-based system for easy extensibility
- âš¡ **TypeScript First** - Full type safety and IntelliSense support
- ğŸ¨ **Framework Agnostic** - Use with React, Vue, or vanilla JavaScript

## ğŸš€ Quick Start

### Installation

```bash
# Clone the repository
git clone https://github.com/zeikar/charivo.git
cd charivo

# Install dependencies
pnpm install

# Build packages
pnpm build

# Run the demo
cd examples/web
pnpm dev
```

### Basic Usage

```typescript
import { Charivo } from "@charivo/core";
import { createOpenAIAdapter } from "@charivo/adapter-llm-openai";
import { createWebTTSAdapter } from "@charivo/adapter-tts-web";
import { Live2DRenderer } from "@charivo/render-live2d";

// Create Charivo instance
const charivo = new Charivo();

// Set up components
const llmAdapter = createOpenAIAdapter("/api/chat");
const ttsAdapter = createWebTTSAdapter();
const renderer = new Live2DRenderer(canvasElement);

// Connect adapters
charivo.attachLLM(llmAdapter);
charivo.attachTTS(ttsAdapter);
charivo.attachRenderer(renderer);

// Add your character
charivo.addCharacter({
  id: "hiyori",
  name: "Hiyori",
  personality: "Cheerful and helpful AI assistant",
  voice: {
    rate: 1.0,
    pitch: 1.2,
    volume: 0.8
  }
});

// Start chatting!
await charivo.userSay("Hello!", "hiyori");
```

## ğŸ“¦ Packages

| Package | Description |
|---------|-------------|
| [`@charivo/core`](./packages/core) | Core framework with event system and character management |
| [`@charivo/adapter-llm-openai`](./packages/adapter-llm-openai) | OpenAI GPT integration |
| [`@charivo/adapter-llm-stub`](./packages/adapter-llm-stub) | Stub adapter for testing |
| [`@charivo/adapter-tts-web`](./packages/adapter-tts-web) | Web Speech API TTS integration |
| [`@charivo/render-live2d`](./packages/render-live2d) | Live2D character rendering |
| [`@charivo/render-stub`](./packages/render-stub) | Stub renderer for testing |
| [`@charivo/shared`](./packages/shared) | Shared utilities and types |

## ğŸ¯ Examples

### Web Demo
A complete Next.js application showcasing all features:
- Live2D character animation
- OpenAI GPT conversation
- Text-to-speech output
- Interactive chat interface

```bash
cd examples/web
pnpm dev
```

Open [http://localhost:3000](http://localhost:3000) to see the demo.

## ğŸ—ï¸ Architecture

Charivo follows a modular, adapter-based architecture:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Your App      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ @charivo/core   â”‚  â†â”€ Event bus, character management
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   Adapters      â”‚  â†â”€ Pluggable components
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚    LLM    â”‚  â”‚  â†â”€ OpenAI, Claude, local models...
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚ Renderer  â”‚  â”‚  â†â”€ Live2D, 3D, sprite-based...
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚    TTS    â”‚  â”‚  â†â”€ Web Speech, Azure, ElevenLabs...
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”§ Creating Custom Adapters

### LLM Adapter
```typescript
import { LLMAdapter, Message, Character } from "@charivo/core";

class CustomLLMAdapter implements LLMAdapter {
  async generateResponse(message: Message): Promise<string> {
    // Your custom LLM logic here
    return "Custom response";
  }

  setCharacter(character: Character): void {
    // Configure your LLM with character context
  }

  clearHistory(): void {
    // Reset conversation history
  }
}
```

### TTS Adapter
```typescript
import { TTSAdapter, TTSOptions } from "@charivo/core";

class CustomTTSAdapter implements TTSAdapter {
  async speak(text: string, options?: TTSOptions): Promise<void> {
    // Your custom TTS implementation
  }

  // Implement other required methods...
}
```

## ğŸ¨ Live2D Setup

1. **Get a Live2D model** (`.model3.json` and assets)
2. **Place in your public directory**
3. **Load the model**:

```typescript
await renderer.loadModel("/path/to/your/model.model3.json");
```

The demo includes a free Hiyori model from Live2D samples.

## ğŸ“š API Reference

### Core Classes

#### `Charivo`
Main orchestrator class that manages all components.

**Methods:**
- `attachLLM(adapter: LLMAdapter)` - Connect LLM provider
- `attachTTS(adapter: TTSAdapter)` - Connect TTS provider  
- `attachRenderer(renderer: Renderer)` - Connect renderer
- `addCharacter(character: Character)` - Add character
- `userSay(message: string, characterId?: string)` - Send user message
- `on(event: string, callback: Function)` - Listen to events

#### Events
- `message:sent` - User sent a message
- `message:received` - Character responded
- `character:speak` - Character is speaking
- `tts:start` - TTS started
- `tts:end` - TTS finished
- `tts:error` - TTS error occurred

## ğŸ¤ Contributing

We welcome contributions! Please see our [Contributing Guide](CONTRIBUTING.md) for details.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- [Live2D](https://www.live2d.com/) for the amazing 2D animation technology
- [pixi-live2d-display](https://github.com/guansss/pixi-live2d-display) for the Live2D integration
- [OpenAI](https://openai.com/) for GPT API
- All contributors and the open source community

---

<div align="center">

**[ğŸŒŸ Star this repo](https://github.com/zeikar/charivo)** â€¢ **[ğŸ“– Documentation](https://github.com/zeikar/charivo/wiki)** â€¢ **[ğŸ› Report Bug](https://github.com/zeikar/charivo/issues)** â€¢ **[ğŸ’¡ Request Feature](https://github.com/zeikar/charivo/issues)**

Made with â¤ï¸ by [zeikar](https://github.com/zeikar)

</div>
